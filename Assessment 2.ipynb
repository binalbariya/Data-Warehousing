{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binal Manoj Bariya (20MAI0075)\n",
    "\n",
    "# Github Link : https://github.com/binalbariya/Data-Warehousing/blob/main/Assessment%202.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Association rule mining:\n",
    "It is a technique to identify underlying relations between different items. Take an example of a Super Market where customers can buy variety of items. Usually, there is a pattern in what the customers buy. In short, transactions involve a pattern. More profit can be generated if the relationship between the items purchased in different transactions can be identified.\n",
    "\n",
    "For instance, if item A and B are bought together more frequently then several steps can be taken to increase the profit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different statistical algorithms have been developed to implement association rule mining, and Apriori is one such algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three major components of Apriori algorithm:\n",
    "\n",
    "Support\n",
    "Confidence\n",
    "Lift\n",
    "\n",
    "Support(B) = (Transactions containing (B))/(Total Transactions)\n",
    "\n",
    "Confidence(A→B) = (Transactions containing both (A and B))/(Transactions containing A)\n",
    "\n",
    "Lift(A→B) = (Confidence (A→B))/(Support (B))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "About the dataset:\n",
    "It is a dataset of different daily life products given 7500 transactions\n",
    "over the course of a week at a French retail store. \n",
    "\n",
    "The dataset can be downloaded from the following link:\n",
    "https://drive.google.com/file/d/1y5DYn0dGoSbC22xowBq2d4po6h1JxcTQ/view\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting apyori\n",
      "  Downloading apyori-1.1.2.tar.gz (8.6 kB)\n",
      "Building wheels for collected packages: apyori\n",
      "  Building wheel for apyori (setup.py): started\n",
      "  Building wheel for apyori (setup.py): finished with status 'done'\n",
      "  Created wheel for apyori: filename=apyori-1.1.2-py3-none-any.whl size=5979 sha256=d76a8cd5aaa3e16a059d7573cefcdcc4dc770ee94b7e16fda62e1545478c1566\n",
      "  Stored in directory: c:\\users\\binal bariya\\appdata\\local\\pip\\cache\\wheels\\cb\\f6\\e1\\57973c631d27efd1a2f375bd6a83b2a616c4021f24aab84080\n",
      "Successfully built apyori\n",
      "Installing collected packages: apyori\n",
      "Successfully installed apyori-1.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install apyori\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the libraries\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from apyori import apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the Dataset\n",
    "#Now let's import the dataset and see what we're working with. \n",
    "#Download the dataset from the given link \n",
    "\n",
    "store_data = pd.read_csv('store_data.csv',header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A snippet of the dataset is shown in the above screenshot. \n",
    "\n",
    "If you carefully look at the data, we can see that the \n",
    "header is actually the first transaction. Each row corresponds \n",
    "to a transaction and each column corresponds to an item \n",
    "purchased in that specific transaction. \n",
    "\n",
    "The NaN tells us that the item represented by the column was not purchased in that specific transaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shrimp</td>\n",
       "      <td>almonds</td>\n",
       "      <td>avocado</td>\n",
       "      <td>vegetables mix</td>\n",
       "      <td>green grapes</td>\n",
       "      <td>whole weat flour</td>\n",
       "      <td>yams</td>\n",
       "      <td>cottage cheese</td>\n",
       "      <td>energy drink</td>\n",
       "      <td>tomato juice</td>\n",
       "      <td>low fat yogurt</td>\n",
       "      <td>green tea</td>\n",
       "      <td>honey</td>\n",
       "      <td>salad</td>\n",
       "      <td>mineral water</td>\n",
       "      <td>salmon</td>\n",
       "      <td>antioxydant juice</td>\n",
       "      <td>frozen smoothie</td>\n",
       "      <td>spinach</td>\n",
       "      <td>olive oil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>burgers</td>\n",
       "      <td>meatballs</td>\n",
       "      <td>eggs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chutney</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>turkey</td>\n",
       "      <td>avocado</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mineral water</td>\n",
       "      <td>milk</td>\n",
       "      <td>energy bar</td>\n",
       "      <td>whole wheat rice</td>\n",
       "      <td>green tea</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0          1           2                 3             4   \\\n",
       "0         shrimp    almonds     avocado    vegetables mix  green grapes   \n",
       "1        burgers  meatballs        eggs               NaN           NaN   \n",
       "2        chutney        NaN         NaN               NaN           NaN   \n",
       "3         turkey    avocado         NaN               NaN           NaN   \n",
       "4  mineral water       milk  energy bar  whole wheat rice     green tea   \n",
       "\n",
       "                 5     6               7             8             9   \\\n",
       "0  whole weat flour  yams  cottage cheese  energy drink  tomato juice   \n",
       "1               NaN   NaN             NaN           NaN           NaN   \n",
       "2               NaN   NaN             NaN           NaN           NaN   \n",
       "3               NaN   NaN             NaN           NaN           NaN   \n",
       "4               NaN   NaN             NaN           NaN           NaN   \n",
       "\n",
       "               10         11     12     13             14      15  \\\n",
       "0  low fat yogurt  green tea  honey  salad  mineral water  salmon   \n",
       "1             NaN        NaN    NaN    NaN            NaN     NaN   \n",
       "2             NaN        NaN    NaN    NaN            NaN     NaN   \n",
       "3             NaN        NaN    NaN    NaN            NaN     NaN   \n",
       "4             NaN        NaN    NaN    NaN            NaN     NaN   \n",
       "\n",
       "                  16               17       18         19  \n",
       "0  antioxydant juice  frozen smoothie  spinach  olive oil  \n",
       "1                NaN              NaN      NaN        NaN  \n",
       "2                NaN              NaN      NaN        NaN  \n",
       "3                NaN              NaN      NaN        NaN  \n",
       "4                NaN              NaN      NaN        NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's call the head() function to see how the dataset looks:\n",
    "store_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Proprocessing\n",
    "\n",
    "The Apriori library we are going to use requires our dataset to be in the form of a list of lists, \n",
    "where the whole dataset is a big list and each transaction in the dataset \n",
    "is an inner list within the outer big list. \n",
    "Currently we have data in the form of a pandas dataframe. \n",
    "To convert our pandas dataframe into a list of lists.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "for i in range(0, 7501):\n",
    "    records.append([str(store_data.values[i,j]) for j in range(0, 20)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying Apriori\n",
    "\n",
    "The next step is to apply the Apriori algorithm on the dataset. \n",
    "To do so, we can use the apriori class that we imported from the apyori library.\n",
    "\n",
    "The apriori class requires some parameter values to work. \n",
    "The first parameter is the list of list that you want to extract rules from. \n",
    "The second parameter is the min_support parameter. \n",
    "This parameter is used to select the items with support values greater than the value specified by the parameter. \n",
    "Next, the min_confidence parameter filters those rules that have confidence \n",
    "greater than the confidence threshold specified by the parameter. \n",
    "\n",
    "Similarly, the min_lift parameter specifies the minimum lift value for the short listed rules. \n",
    "Finally, the min_length parameter specifies the minimum number of items that you want in your rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "association_rules = apriori(records, min_support=0.0045, min_confidence=0.2, min_lift=3, min_length=2)\n",
    "association_results = list(association_rules)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now taking hand-made dataset for implementing association rule mining "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using both  Apriori and F-P growth algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlxtend\n",
      "  Downloading mlxtend-0.18.0-py2.py3-none-any.whl (1.3 MB)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\binal bariya\\anaconda3\\lib\\site-packages (from mlxtend) (0.17.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\binal bariya\\anaconda3\\lib\\site-packages (from mlxtend) (50.3.0.post20201006)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\users\\binal bariya\\anaconda3\\lib\\site-packages (from mlxtend) (1.5.2)\n",
      "Requirement already satisfied: scikit-learn>=0.20.3 in c:\\users\\binal bariya\\anaconda3\\lib\\site-packages (from mlxtend) (0.23.2)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\binal bariya\\anaconda3\\lib\\site-packages (from mlxtend) (1.19.1)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\binal bariya\\anaconda3\\lib\\site-packages (from mlxtend) (1.1.3)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\binal bariya\\anaconda3\\lib\\site-packages (from mlxtend) (3.3.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\binal bariya\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.3->mlxtend) (2.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\binal bariya\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\binal bariya\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2020.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\binal bariya\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (7.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\binal bariya\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\binal bariya\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\binal bariya\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.10.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in c:\\users\\binal bariya\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2020.6.20)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\binal bariya\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas>=0.24.2->mlxtend) (1.15.0)\n",
      "Installing collected packages: mlxtend\n",
      "Successfully installed mlxtend-0.18.0\n"
     ]
    }
   ],
   "source": [
    "!pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a hand made list with the required data\n",
    "\n",
    "dataset = [['Milk', 'Eggs', 'Bread'],\n",
    "['Milk', 'Eggs'],\n",
    "['Milk', 'Bread'],\n",
    "['Eggs', 'Apple']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Milk', 'Eggs', 'Bread'], ['Milk', 'Eggs'], ['Milk', 'Bread'], ['Eggs', 'Apple']]\n"
     ]
    }
   ],
   "source": [
    "#lets look at the dataset\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert list to dataframe with boolean values\n",
    "\n",
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "te = TransactionEncoder()\n",
    "te_array = te.fit(dataset).transform(dataset)\n",
    "df = pd.DataFrame(te_array, columns=te.columns_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Apple  Bread   Eggs   Milk\n",
      "0  False   True   True   True\n",
      "1  False  False   True   True\n",
      "2  False   True  False   True\n",
      "3   True  False   True  False\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we import the apriori algorithm function from the library.\n",
    "\n",
    "Then we apply the algorithm to our data to extract the itemsets that\n",
    "have a minimum support value of 0.01 (this parameter can be changed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now Find frequently occurring itemsets using Apriori Algorithm\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "\n",
    "frequent_itemsets_ap = apriori(df, min_support=0.01, use_colnames=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   support             itemsets\n",
      "0     0.25              (Apple)\n",
      "1     0.50              (Bread)\n",
      "2     0.75               (Eggs)\n",
      "3     0.75               (Milk)\n",
      "4     0.25        (Eggs, Apple)\n",
      "5     0.25        (Eggs, Bread)\n",
      "6     0.50        (Milk, Bread)\n",
      "7     0.50         (Milk, Eggs)\n",
      "8     0.25  (Milk, Eggs, Bread)\n"
     ]
    }
   ],
   "source": [
    "#Viewing the results\n",
    "\n",
    "print(frequent_itemsets_ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import the F-P growth algorithm function from the library.\n",
    "Then we apply the algorithm to our data to extract the itemsets that have a minimum support value of 0.01 (this parameter can be tuned on a case-by-case basis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find frequently occurring itemsets using F-P Growth\n",
    "\n",
    "from mlxtend.frequent_patterns import fpgrowth\n",
    "\n",
    "frequent_itemsets_fp=fpgrowth(df, min_support=0.01, use_colnames=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   support             itemsets\n",
      "0     0.75               (Milk)\n",
      "1     0.75               (Eggs)\n",
      "2     0.50              (Bread)\n",
      "3     0.25              (Apple)\n",
      "4     0.50         (Milk, Eggs)\n",
      "5     0.50        (Milk, Bread)\n",
      "6     0.25        (Eggs, Bread)\n",
      "7     0.25  (Milk, Eggs, Bread)\n",
      "8     0.25        (Eggs, Apple)\n"
     ]
    }
   ],
   "source": [
    "#Viewing the results\n",
    "\n",
    "print(frequent_itemsets_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Mine the association rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "rules_ap = association_rules(frequent_itemsets_ap, metric=\"confidence\", min_threshold=0.8)\n",
    "rules_fp = association_rules(frequent_itemsets_fp, metric=\"confidence\", min_threshold=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     antecedents consequents  antecedent support  consequent support  support  \\\n",
      "0        (Apple)      (Eggs)                0.25                0.75     0.25   \n",
      "1        (Bread)      (Milk)                0.50                0.75     0.50   \n",
      "2  (Eggs, Bread)      (Milk)                0.25                0.75     0.25   \n",
      "\n",
      "   confidence      lift  leverage  conviction  \n",
      "0         1.0  1.333333    0.0625         inf  \n",
      "1         1.0  1.333333    0.1250         inf  \n",
      "2         1.0  1.333333    0.0625         inf  \n"
     ]
    }
   ],
   "source": [
    "#set of rules generated by apriori algorithm\n",
    "print(rules_ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     antecedents consequents  antecedent support  consequent support  support  \\\n",
      "0        (Bread)      (Milk)                0.50                0.75     0.50   \n",
      "1  (Eggs, Bread)      (Milk)                0.25                0.75     0.25   \n",
      "2        (Apple)      (Eggs)                0.25                0.75     0.25   \n",
      "\n",
      "   confidence      lift  leverage  conviction  \n",
      "0         1.0  1.333333    0.1250         inf  \n",
      "1         1.0  1.333333    0.0625         inf  \n",
      "2         1.0  1.333333    0.0625         inf  \n"
     ]
    }
   ],
   "source": [
    "#set of rules generated by FP algorithm\n",
    "print(rules_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
